{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Input, SimpleRNN # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "from NeuralNetworks.PreProcessing import preprocess_data, learning_set\n",
    "from NeuralNetworks.PostProcessing import plot_test_and_prediction\n",
    "from NeuralNetworks.LearningInstance import LearningInstance\n",
    "from NeuralNetworks.Predictions import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 113\n",
    "T = 118\n",
    "q = 31\n",
    "q0 = 16\n",
    "\n",
    "names_path = \"Data/names.txt\"\n",
    "gdp_path = \"Data/yp_raw.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "with open(names_path, 'r') as file:\n",
    "    rows = file.readlines()\n",
    "    for row in rows:\n",
    "        names.append(row[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = np.zeros((n,T))\n",
    "with open(gdp_path, 'r') as file:\n",
    "    rows = csv.reader(file)\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, val in enumerate(row):\n",
    "            gdp[j][i] = float(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gdp, low_gdp = preprocess_data(gdp, T, q, q0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 10\n",
    "split = 0.7\n",
    "horizon = 50\n",
    "learning_sets: list[LearningInstance] = learning_set(\n",
    "    lags, split, gdp, log_gdp, low_gdp, names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [Real(1e-6, 1e-2, \"log-uniform\", name='learning_rate'),\n",
    "         Integer(1, 5, name='num_layers'),\n",
    "         Integer(10, 500, name='num_units')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = learning_sets[0]\n",
    "usa = learning_sets[names.index(\"USA\")]\n",
    "print(country.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP(learning_rate, num_layers, num_units, lags):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(lags,)))\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(int(num_units), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate), \n",
    "        loss = 'mean_squared_error'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RNN(learning_rate, num_layers, num_units, lags):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(lags,1)))\n",
    "\n",
    "    # Add LSTM layers\n",
    "    for i in range(num_layers):\n",
    "            model.add(SimpleRNN(int(num_units), return_sequences=i<num_layers-1))\n",
    "    \n",
    "    # Output layer for regression\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_MLP(params):\n",
    "    learning_rate, num_layers, num_units = params\n",
    "    num_units = int(num_units)\n",
    "    model = build_MLP(learning_rate, num_layers, num_units, lags)\n",
    "    history = model.fit(\n",
    "        country.x_train, \n",
    "        country.y_train, \n",
    "        validation_data = (country.x_test, country.y_test), \n",
    "        epochs = 50, \n",
    "        batch_size = 32,\n",
    "        verbose = 0\n",
    "    )\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    # Return the validation loss (or any metric to minimize)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_RNN(params):\n",
    "    learning_rate, num_layers, num_units = params\n",
    "    num_units = int(num_units)\n",
    "    model = build_RNN(learning_rate, num_layers, num_units, lags)\n",
    "    history = model.fit(\n",
    "        country.x_train.reshape(country.x_train.shape[0], country.x_train.shape[1], 1), \n",
    "        country.y_train, \n",
    "        validation_data = (country.x_test.reshape(country.x_test.shape[0], country.x_test.shape[1],1), country.y_test), \n",
    "        epochs = 50, \n",
    "        batch_size = 32,\n",
    "        verbose = 0\n",
    "    )\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    # Return the validation loss (or any metric to minimize)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mlp = gp_minimize(objective_MLP, space, n_calls=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_mlp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized = build_MLP(result_mlp.x[0], result_mlp.x[1], result_mlp.x[2], lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimized.fit(\n",
    "    country.x_train, \n",
    "    country.y_train, \n",
    "    validation_data = (country.x_test, country.y_test), \n",
    "    epochs = 50, \n",
    "    batch_size = 32,\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = optimized.evaluate(country.x_test, country.y_test, verbose=0)\n",
    "test_predictions = optimized.predict(country.x_test, verbose=0).T[0]\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_RNN(model: Sequential, \n",
    "            inst: LearningInstance, \n",
    "            lags: int, \n",
    "            horizon: int\n",
    "            ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs iterative predictions for a given neural network\n",
    "\n",
    "    Parameters:\n",
    "    model (Sequential): The neural network with which predictions are performed\n",
    "    inst (LearningInstance): The learning instance (country) to predict for\n",
    "    lags (int): the amount of previous values to be considered\n",
    "    horizon (int): the amount of future values to be predicted\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The forecasted values\n",
    "    \"\"\"\n",
    "    last = inst.low_freq[-lags:]\n",
    "    future = np.zeros(horizon)\n",
    "    for i in range(horizon):\n",
    "        p = model.predict(last.reshape(1,lags,1), verbose=0)[0][0]\n",
    "        future[i] = p\n",
    "        last = np.roll(last,-1)\n",
    "        last[-1] = p\n",
    "    return future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = predict(optimized, country, lags, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_and_prediction(country, test_predictions, future, \"MLP Predictions for ARG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_usa = optimized.fit(\n",
    "    usa.x_train, \n",
    "    usa.y_train, \n",
    "    validation_data = (usa.x_test, usa.y_test), \n",
    "    epochs = 50, \n",
    "    batch_size = 32,\n",
    "    verbose = 0\n",
    ")\n",
    "loss_usa = optimized.evaluate(usa.x_test, usa.y_test, verbose=0)\n",
    "test_predictions_usa = optimized.predict(usa.x_test, verbose=0).T[0]\n",
    "print(loss_usa)\n",
    "future_usa = predict(optimized, usa, lags, horizon)\n",
    "plot_test_and_prediction(usa, test_predictions_usa, future_usa, \"MLP predictions for USA (from ARG-tuned model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_usa(params):\n",
    "    learning_rate, num_layers, num_units = params\n",
    "    num_units = int(num_units)\n",
    "    model = build_MLP(learning_rate, num_layers, num_units, lags)\n",
    "    history = model.fit(\n",
    "        usa.x_train, \n",
    "        usa.y_train, \n",
    "        validation_data = (usa.x_test, usa.y_test), \n",
    "        epochs = 50, \n",
    "        batch_size = 32,\n",
    "        verbose = 0\n",
    "    )\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    # Return the validation loss (or any metric to minimize)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_usa = gp_minimize(objective_usa, space, n_calls=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_usa = build_MLP(result_usa.x[0], result_usa.x[1], result_usa.x[2], lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_usa1 = optimized_usa.fit(\n",
    "    usa.x_train, \n",
    "    usa.y_train, \n",
    "    validation_data = (usa.x_test, usa.y_test), \n",
    "    epochs = 50, \n",
    "    batch_size = 32,\n",
    "    verbose = 0\n",
    ")\n",
    "loss_usa1 = optimized_usa.evaluate(usa.x_test, usa.y_test, verbose=0)\n",
    "test_predictions_usa1 = optimized_usa.predict(usa.x_test, verbose=0).T[0]\n",
    "print(loss_usa1)\n",
    "future_usa1 = predict(optimized_usa, usa, lags, horizon)\n",
    "plot_test_and_prediction(usa, test_predictions_usa1, future_usa1, \"MLP predictions for USA (from USA-tuned model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rnn = gp_minimize(objective_RNN, space, n_calls=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_rnn.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_rnn = build_RNN(result_mlp.x[0], result_mlp.x[1], result_mlp.x[2], lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnn = optimized_rnn.fit(\n",
    "    country.x_train.reshape(country.x_train.shape[0], country.x_train.shape[1], 1), \n",
    "    country.y_train, \n",
    "    validation_data = (country.x_test.reshape(country.x_test.shape[0], country.x_test.shape[1],1), country.y_test), \n",
    "    epochs = 50, \n",
    "    batch_size = 32,\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rnn = optimized_rnn.evaluate(country.x_test.reshape(country.x_test.shape[0], country.x_test.shape[1], 1), country.y_test, verbose=0)\n",
    "test_predictions_rnn = optimized_rnn.predict(country.x_test.reshape(country.x_test.shape[0], country.x_test.shape[1], 1), verbose=0).T[0]\n",
    "print(loss_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_rnn = predict_RNN(optimized_rnn, country, lags, horizon)\n",
    "plot_test_and_prediction(country, test_predictions_rnn, future_rnn, \"RNN prediction for ARG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
